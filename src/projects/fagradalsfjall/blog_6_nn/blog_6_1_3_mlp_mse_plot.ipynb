{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.projects.fagradalsfjall.common.model_eval import ModelEvalResult, ValidationType\n",
    "from src.projects.fagradalsfjall.common.model_eval_plot_curves import generate_all_rmse_plots\n",
    "from src.projects.fagradalsfjall.common.model_eval_plot_simulations import plot_simulations\n",
    "from src.projects.fagradalsfjall.common.model_repo import ModelRepo\n",
    "from src.projects.fagradalsfjall.common.paths import get_blog_post_subfolder\n",
    "from src.projects.fagradalsfjall.common.project_settings import TS_PRIMARY_METRIC_DISPLAY_NAME\n",
    "from src.tools.datetime import format_timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "#  Output path settings\n",
    "# -------------------------------------------------------------------------\n",
    "path_results_mlp_mse = get_blog_post_subfolder(6, \"results_1_mlp_mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "#  Load data\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# --- load models -------------------------------------\n",
    "prev_model_eval_results = ModelRepo.load_models([\"naive-mean\", \"naive-constant\", \"naive-exp-decay\", \"linear-ar\"])\n",
    "\n",
    "# load mlp-mse results\n",
    "mlp_mse_model_eval_results = ModelRepo.load_models([\"mlp-rmse\"])\n",
    "mlp_mse_n_1_model_eval_results = ModelRepo.load_models([\"mlp-rmse-n-1\"])\n",
    "mlp_mse_n_192_model_eval_results = ModelRepo.load_models([\"mlp-rmse-n-192\"])\n",
    "\n",
    "# rename\n",
    "mlp_mse_model_eval_results = {\"mlp-mse\": mlp_mse_model_eval_results[\"mlp-rmse\"]}\n",
    "mlp_mse_n_1_model_eval_results = {\"mlp-mse-n-1\": mlp_mse_n_1_model_eval_results[\"mlp-rmse-n-1\"]}\n",
    "mlp_mse_n_192_model_eval_results = {\"mlp-mse-n-192\": mlp_mse_n_192_model_eval_results[\"mlp-rmse-n-192\"]}\n",
    "\n",
    "# --- post-processing ---------------------------------\n",
    "model_mlp_mse = mlp_mse_model_eval_results[\"mlp-mse\"].ts_model\n",
    "model_mlp_mse_n_1 = mlp_mse_n_1_model_eval_results[\"mlp-mse-n-1\"].ts_model\n",
    "model_mlp_mse_n_192 = mlp_mse_n_192_model_eval_results[\"mlp-mse-n-192\"].ts_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "#  Overall grid search 1D results\n",
    "# -------------------------------------------------------------------------\n",
    "param_names = [\"n_epochs\", \"n_hidden_layers\", \"dropout\", \"n\"]\n",
    "\n",
    "for param_name in param_names:\n",
    "\n",
    "    fig, ax = (\n",
    "        model_mlp_mse.cv.results.plot_1d(param_names=param_name)\n",
    "        .set_fig_title(f\"Cross-validation - 'mlp-mse' - best results for each value of '{param_name}'\")\n",
    "        .set_y_label(TS_PRIMARY_METRIC_DISPLAY_NAME)\n",
    "        .set_x_label(param_name)\n",
    "        .create(w=12, h=8)\n",
    "    )\n",
    "    fig.savefig(path_results_mlp_mse / f\"cv_1d_best_{param_name}.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "#  RMSE curves for n=1 & 192\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# merge all evaluation results in single dict for visualization\n",
    "model_eval_results = prev_model_eval_results | mlp_mse_n_1_model_eval_results | mlp_mse_n_192_model_eval_results\n",
    "\n",
    "# create RMSE plots\n",
    "generate_all_rmse_plots(model_eval_results, path_results_mlp_mse, highlight_models=[\"mlp-mse-n-1\", \"mlp-mse-n-192\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "#  Simulations for n=1 & n=192\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# simulations\n",
    "plot_simulations(mlp_mse_n_1_model_eval_results | mlp_mse_n_192_model_eval_results, path_results_mlp_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_metrics = ModelEvalResult.all_metric_values_as_df(model_eval_results, ValidationType.TEST)\n",
    "\n",
    "df_metrics[\"max_accurate_lead_time_samples\"] = df_metrics[\"max_accurate_lead_time\"].copy()\n",
    "df_metrics[\"max_accurate_lead_time\"] = df_metrics[\"max_accurate_lead_time\"].apply(\n",
    "    lambda x: format_timedelta(x * 15 * 60)\n",
    ")\n",
    "\n",
    "display(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "#  Final parameters\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "for n, model in [(1, model_mlp_mse_n_1), (192, model_mlp_mse_n_192)]:\n",
    "\n",
    "    print()\n",
    "    print(\"=================================\")\n",
    "    print(f\" n={n}\")\n",
    "    print(\"=================================\")\n",
    "    print(f\"metric: {model_mlp_mse.cv.results.filter(param_filter=dict(n=n)).best_result.val_metrics.overall:.3f}\")\n",
    "    print()\n",
    "\n",
    "    for param_name, param_value in model.get_params().items():\n",
    "        print(f\"{param_name} : \".rjust(20) + str(param_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
